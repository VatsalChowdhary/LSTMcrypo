{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN+ABde1mxj+J4cBcsG5Gwl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install arch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zv-Vuh4Y5soD","executionInfo":{"status":"ok","timestamp":1682214370057,"user_tz":-330,"elapsed":5505,"user":{"displayName":"Vatsal Chowdhary","userId":"11960625794539825838"}},"outputId":"efda359f-d077-4493-d086-c9abc979311e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting arch\n","  Downloading arch-5.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.5/920.5 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting property-cached>=1.6.4\n","  Downloading property_cached-1.6.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: statsmodels>=0.11 in /usr/local/lib/python3.9/dist-packages (from arch) (0.13.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from arch) (1.22.4)\n","Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.9/dist-packages (from arch) (1.10.1)\n","Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.9/dist-packages (from arch) (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0->arch) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0->arch) (2022.7.1)\n","Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.11->arch) (0.5.3)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.11->arch) (23.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy>=0.5.2->statsmodels>=0.11->arch) (1.16.0)\n","Installing collected packages: property-cached, arch\n","Successfully installed arch-5.4.0 property-cached-1.6.4\n"]}]},{"cell_type":"code","source":["# data1 = pd.read_csv('Bitcoin_modified')\n","# data1 = data1.drop('Unnamed: 0', axis=1)\n","# returns = abs(100 * data1['Close'].pct_change().fillna(0))\n","# ten_day_vol = []\n","# for i in range(0, 4419):\n","#     ten_day_vol.append(returns[i:i+10].std())\n","# data1['ten_day_vol'] = pd.Series(ten_day_vol, index = range(0,4419))\n","# data1 = data1.fillna(0)\n","# data1.isnull().values.any()\n","# # Split the data into train and test sets\n","# train_data, test_data = train_test_split(data1, test_size=0.2, shuffle=False)\n","# features = (train_data[['Garch Estimation', 'Previous 30 day Volatility', 'Previous 10 day Volatility', 'Log Return', 'Log Trading Range', 'Log Volume Change']])\n","# target = train_data['ten_day_vol']\n","# target2 = test_data['ten_day_vol']\n","# # # Define the number of input columns\n","# n_input = 6\n","\n","# # # Define the number of hidden units in the LSTM layer\n","# n_units = 10\n","\n","# # # Define the optimizer\n","# optimizer = Adam(lr=0.0)\n","\n","# # # Define the loss function\n","# loss = 'mean_squared_error'\n","\n","# # # Define the LSTM model\n","# model = Sequential()\n","# model.add(LSTM(units=n_units, input_shape=(n_input, 1)))\n","# model.add(Dense(units=1))\n","\n","# # # Compile the model\n","# model.compile(optimizer=optimizer, loss=loss)\n","\n","# #Reshape the training data\n","# X_train = np.array(train_data.iloc[:, 7:13]).reshape(-1, n_input, 1)\n","\n","# y_train = np.array(target)\n","# #Train the model\n","# model.fit(X_train, y_train, epochs=100, batch_size=50)\n","\n","# # # Reshape the test data\n","# X_test = np.array(test_data.iloc[:, 7:13]).reshape(-1, n_input, 1)\n","# y_test = np.array(target2)\n","\n","# # # Evaluate the model on the test data\n","# test_loss = model.evaluate(X_test, y_test)\n","# print(f'Test loss: {test_loss}')\n","# # data1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":133},"id":"uW1osY2sy_dO","executionInfo":{"status":"error","timestamp":1682082001939,"user_tz":-330,"elapsed":417,"user":{"displayName":"Vatsal Chowdhary","userId":"11960625794539825838"}},"outputId":"8a6e2703-dc58-4c66-8914-8b4866e5b7c2"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-88a719eb66a3>\"\u001b[0;36m, line \u001b[0;32m50\u001b[0m\n\u001b[0;31m    pip instal arch\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1C1fEZtDy0wX"},"outputs":[],"source":["from datetime import datetime, timedelta\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from arch import arch_model\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","import numpy as np\n","from arch.__future__ import reindexing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout, Bidirectional, Activation, LSTM\n","from keras.optimizers import Adam\n","import keras"]},{"cell_type":"code","source":["csv_path = \"https://raw.githubusercontent.com/curiousily/Deep-Learning-For-Hackers/master/data/3.stock-prediction/BTC-USD.csv\"\n","df = pd.read_csv(csv_path, parse_dates=['Date'])\n","df = df.sort_values('Date')\n","scaler = MinMaxScaler()\n","\n","close_price = df.Close.values.reshape(-1, 1)\n","\n","scaled_close = scaler.fit_transform(close_price)\n","scaled_close = scaled_close[~np.isnan(scaled_close)]\n","scaled_close = scaled_close.reshape(-1, 1)\n","SEQ_LEN = 100\n","\n","def to_sequences(data, seq_len):\n","    d = []\n","\n","    for index in range(len(data) - seq_len):\n","        d.append(data[index: index + seq_len])\n","\n","    return np.array(d)\n","\n","def preprocess(data_raw, seq_len, train_split):\n","\n","    data = to_sequences(data_raw, seq_len)\n","\n","    num_train = int(train_split * data.shape[0])\n","\n","    X_train = data[:num_train, :-1, :]\n","    y_train = data[:num_train, -1, :]\n","\n","    X_test = data[num_train:, :-1, :]\n","    y_test = data[num_train:, -1, :]\n","\n","    return X_train, y_train, X_test, y_test\n","\n","\n","X_train, y_train, X_test, y_test =\\\n"," preprocess(scaled_close, SEQ_LEN, train_split = 0.95)\n","DROPOUT = 0.2\n","WINDOW_SIZE = SEQ_LEN - 1\n","model = keras.Sequential()\n","model.add(Bidirectional(LSTM(WINDOW_SIZE, return_sequences=True),\n","  input_shape=(WINDOW_SIZE, X_train.shape[-1])\n","))\n","model.add(Dropout(rate=DROPOUT))\n","\n","model.add(Bidirectional(\n","  LSTM((WINDOW_SIZE * 2), return_sequences=True)\n","))\n","model.add(Dropout(rate=DROPOUT))\n","\n","model.add(Bidirectional(\n","  LSTM(WINDOW_SIZE, return_sequences=False)\n","))\n","\n","model.add(Dense(units=1))\n","\n","model.add(Activation('linear'))\n","BATCH_SIZE = 64\n","\n","model.compile(\n","    loss='mean_absolute_error',\n","    optimizer='adam'\n",")\n","\n","history = model.fit(\n","    X_train,\n","    y_train,\n","    epochs=50,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    validation_split=0.1\n",")\n","\n","y_hat = model.predict(X_test)\n","y_test_inverse = scaler.inverse_transform(y_test)\n","y_hat_inverse = scaler.inverse_transform(y_hat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KXVQAjlXzjRg","executionInfo":{"status":"ok","timestamp":1682148666216,"user_tz":-330,"elapsed":3763843,"user":{"displayName":"Vatsal Chowdhary","userId":"11960625794539825838"}},"outputId":"4ff53fc2-0072-479c-a09a-712a94687ed1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","42/42 [==============================] - 92s 2s/step - loss: 0.0254 - val_loss: 0.6280\n","Epoch 2/50\n","42/42 [==============================] - 77s 2s/step - loss: 0.0458 - val_loss: 0.0681\n","Epoch 3/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0338 - val_loss: 0.5509\n","Epoch 4/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0313 - val_loss: 0.0700\n","Epoch 5/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0421 - val_loss: 0.2082\n","Epoch 6/50\n","42/42 [==============================] - 73s 2s/step - loss: 0.0145 - val_loss: 0.1163\n","Epoch 7/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0350 - val_loss: 0.2968\n","Epoch 8/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0393 - val_loss: 0.2105\n","Epoch 9/50\n","42/42 [==============================] - 74s 2s/step - loss: 0.0198 - val_loss: 0.0294\n","Epoch 10/50\n","42/42 [==============================] - 78s 2s/step - loss: 0.0318 - val_loss: 0.1233\n","Epoch 11/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0325 - val_loss: 0.1851\n","Epoch 12/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0158 - val_loss: 0.1220\n","Epoch 13/50\n","42/42 [==============================] - 73s 2s/step - loss: 0.0350 - val_loss: 0.3117\n","Epoch 14/50\n","42/42 [==============================] - 76s 2s/step - loss: 0.0418 - val_loss: 0.2567\n","Epoch 15/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0336 - val_loss: 0.1573\n","Epoch 16/50\n","42/42 [==============================] - 77s 2s/step - loss: 0.0168 - val_loss: 0.1207\n","Epoch 17/50\n","42/42 [==============================] - 77s 2s/step - loss: 0.0360 - val_loss: 0.3142\n","Epoch 18/50\n","42/42 [==============================] - 74s 2s/step - loss: 0.0386 - val_loss: 0.2835\n","Epoch 19/50\n","42/42 [==============================] - 74s 2s/step - loss: 0.0374 - val_loss: 0.2356\n","Epoch 20/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0314 - val_loss: 0.1092\n","Epoch 21/50\n","42/42 [==============================] - 73s 2s/step - loss: 0.0242 - val_loss: 0.1328\n","Epoch 22/50\n","42/42 [==============================] - 74s 2s/step - loss: 0.0374 - val_loss: 0.3200\n","Epoch 23/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0379 - val_loss: 0.2889\n","Epoch 24/50\n","42/42 [==============================] - 74s 2s/step - loss: 0.0372 - val_loss: 0.2482\n","Epoch 25/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0342 - val_loss: 0.1630\n","Epoch 26/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0135 - val_loss: 0.0657\n","Epoch 27/50\n","42/42 [==============================] - 74s 2s/step - loss: 0.0321 - val_loss: 0.2740\n","Epoch 28/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0314 - val_loss: 0.2176\n","Epoch 29/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0271 - val_loss: 0.1014\n","Epoch 30/50\n","42/42 [==============================] - 74s 2s/step - loss: 0.0123 - val_loss: 0.0463\n","Epoch 31/50\n","42/42 [==============================] - 74s 2s/step - loss: 0.0303 - val_loss: 0.2467\n","Epoch 32/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0308 - val_loss: 0.1678\n","Epoch 33/50\n","42/42 [==============================] - 73s 2s/step - loss: 0.0168 - val_loss: 0.0280\n","Epoch 34/50\n","42/42 [==============================] - 74s 2s/step - loss: 0.0290 - val_loss: 0.0396\n","Epoch 35/50\n","42/42 [==============================] - 74s 2s/step - loss: 0.0295 - val_loss: 0.2561\n","Epoch 36/50\n","42/42 [==============================] - 73s 2s/step - loss: 0.0310 - val_loss: 0.1734\n","Epoch 37/50\n","42/42 [==============================] - 74s 2s/step - loss: 0.0179 - val_loss: 0.0177\n","Epoch 38/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0236 - val_loss: 0.0197\n","Epoch 39/50\n","42/42 [==============================] - 76s 2s/step - loss: 0.0269 - val_loss: 0.2394\n","Epoch 40/50\n","42/42 [==============================] - 73s 2s/step - loss: 0.0287 - val_loss: 0.1450\n","Epoch 41/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0162 - val_loss: 0.0236\n","Epoch 42/50\n","42/42 [==============================] - 76s 2s/step - loss: 0.0211 - val_loss: 0.0418\n","Epoch 43/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0255 - val_loss: 0.1964\n","Epoch 44/50\n","42/42 [==============================] - 74s 2s/step - loss: 0.0221 - val_loss: 0.0910\n","Epoch 45/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0089 - val_loss: 0.0333\n","Epoch 46/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0067 - val_loss: 0.0354\n","Epoch 47/50\n","42/42 [==============================] - 77s 2s/step - loss: 0.0080 - val_loss: 0.0288\n","Epoch 48/50\n","42/42 [==============================] - 73s 2s/step - loss: 0.0164 - val_loss: 0.0220\n","Epoch 49/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0178 - val_loss: 0.0600\n","Epoch 50/50\n","42/42 [==============================] - 75s 2s/step - loss: 0.0228 - val_loss: 0.1698\n","5/5 [==============================] - 5s 286ms/step\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lAr8ru4DymHW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["csv_path = \"https://raw.githubusercontent.com/curiousily/Deep-Learning-For-Hackers/master/data/3.stock-prediction/BTC-USD.csv\"\n","df = pd.read_csv('bitcoin.csv', parse_dates=['Date'])\n","df = df.sort_values('Date')\n","scaler = MinMaxScaler()\n","\n","close_price = df.Close.values.reshape(-1, 1)\n","\n","scaled_close = scaler.fit_transform(close_price)\n","scaled_close = scaled_close[~np.isnan(scaled_close)]\n","scaled_close = scaled_close.reshape(-1, 1)\n","SEQ_LEN = 100\n","\n","def to_sequences(data, seq_len):\n","    d = []\n","\n","    for index in range(len(data) - seq_len):\n","        d.append(data[index: index + seq_len])\n","\n","    return np.array(d)\n","\n","def preprocess(data_raw, seq_len, train_split):\n","\n","    data = to_sequences(data_raw, seq_len)\n","\n","    num_train = int(train_split * data.shape[0])\n","\n","    X_train = data[:num_train, :-1, :]\n","    y_train = data[:num_train, -1, :]\n","\n","    X_test = data[num_train:, :-1, :]\n","    y_test = data[num_train:, -1, :]\n","\n","    return X_train, y_train, X_test, y_test\n","\n","\n","X_train, y_train, X_test, y_test =\\\n"," preprocess(scaled_close, SEQ_LEN, train_split = 0.95)\n","DROPOUT = 0.2\n","WINDOW_SIZE = SEQ_LEN - 1\n","model = keras.Sequential()\n","model.add(Bidirectional(LSTM(WINDOW_SIZE, return_sequences=True),\n","  input_shape=(WINDOW_SIZE, X_train.shape[-1])\n","))\n","model.add(Dropout(rate=DROPOUT))\n","\n","model.add(Bidirectional(\n","  LSTM((WINDOW_SIZE * 2), return_sequences=True)\n","))\n","model.add(Dropout(rate=DROPOUT))\n","\n","model.add(Bidirectional(\n","  LSTM(WINDOW_SIZE, return_sequences=False)\n","))\n","\n","model.add(Dense(units=1))\n","\n","model.add(Activation('linear'))\n","BATCH_SIZE = 64\n","\n","model.compile(\n","    loss='mean_absolute_error',\n","    optimizer='adam'\n",")\n","\n","history = model.fit(\n","    X_train,\n","    y_train,\n","    epochs=50,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    validation_split=0.1\n",")\n","\n","y_hat = model.predict(X_test)\n","y_test_inverse = scaler.inverse_transform(y_test)\n","y_hat_inverse = scaler.inverse_transform(y_hat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D2G4fyzwNG10","executionInfo":{"status":"ok","timestamp":1682232298566,"user_tz":-330,"elapsed":3156794,"user":{"displayName":"Vatsal Chowdhary","userId":"11960625794539825838"}},"outputId":"423efeed-e91a-4e56-c80a-8bac4f805f73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","58/58 [==============================] - 75s 1s/step - loss: 0.0163 - val_loss: 0.2505\n","Epoch 2/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0170 - val_loss: 0.0924\n","Epoch 3/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0147 - val_loss: 0.3943\n","Epoch 4/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0144 - val_loss: 0.0540\n","Epoch 5/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0186 - val_loss: 0.3807\n","Epoch 6/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0165 - val_loss: 0.1463\n","Epoch 7/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0199 - val_loss: 0.4955\n","Epoch 8/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0094 - val_loss: 0.0496\n","Epoch 9/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0124 - val_loss: 0.0858\n","Epoch 10/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0102 - val_loss: 0.2467\n","Epoch 11/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0066 - val_loss: 0.2372\n","Epoch 12/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0119 - val_loss: 0.0941\n","Epoch 13/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0107 - val_loss: 0.2687\n","Epoch 14/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0152 - val_loss: 0.1104\n","Epoch 15/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0217 - val_loss: 0.3452\n","Epoch 16/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0184 - val_loss: 0.0698\n","Epoch 17/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0131 - val_loss: 0.0364\n","Epoch 18/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0117 - val_loss: 0.1862\n","Epoch 19/50\n","58/58 [==============================] - 64s 1s/step - loss: 0.0075 - val_loss: 0.3056\n","Epoch 20/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0105 - val_loss: 0.1646\n","Epoch 21/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0100 - val_loss: 0.0588\n","Epoch 22/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0118 - val_loss: 0.0899\n","Epoch 23/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0094 - val_loss: 0.0381\n","Epoch 24/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0116 - val_loss: 0.1271\n","Epoch 25/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0086 - val_loss: 0.0384\n","Epoch 26/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0075 - val_loss: 0.0320\n","Epoch 27/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0065 - val_loss: 0.0940\n","Epoch 28/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0080 - val_loss: 0.0282\n","Epoch 29/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0075 - val_loss: 0.0638\n","Epoch 30/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0054 - val_loss: 0.0796\n","Epoch 31/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0084 - val_loss: 0.0231\n","Epoch 32/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0088 - val_loss: 0.0669\n","Epoch 33/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0083 - val_loss: 0.0320\n","Epoch 34/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0071 - val_loss: 0.0739\n","Epoch 35/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0081 - val_loss: 0.0226\n","Epoch 36/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0083 - val_loss: 0.0658\n","Epoch 37/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0055 - val_loss: 0.1486\n","Epoch 38/50\n","58/58 [==============================] - 64s 1s/step - loss: 0.0051 - val_loss: 0.0865\n","Epoch 39/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0080 - val_loss: 0.0252\n","Epoch 40/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0079 - val_loss: 0.0644\n","Epoch 41/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0061 - val_loss: 0.1339\n","Epoch 42/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0057 - val_loss: 0.0298\n","Epoch 43/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0074 - val_loss: 0.0222\n","Epoch 44/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0092 - val_loss: 0.0718\n","Epoch 45/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0085 - val_loss: 0.0387\n","Epoch 46/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0095 - val_loss: 0.0484\n","Epoch 47/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0077 - val_loss: 0.0365\n","Epoch 48/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0100 - val_loss: 0.0281\n","Epoch 49/50\n","58/58 [==============================] - 62s 1s/step - loss: 0.0076 - val_loss: 0.0469\n","Epoch 50/50\n","58/58 [==============================] - 63s 1s/step - loss: 0.0084 - val_loss: 0.0336\n","7/7 [==============================] - 3s 170ms/step\n"]}]},{"cell_type":"code","source":["arr = []\n","for i in range(0, len(y_hat_inverse)-10):\n","        arr.append((y_hat_inverse[i:i+10].std()))"],"metadata":{"id":"HyziMtbPNL-W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arr1 = []\n","for i in range(0, len(y_test_inverse)-10):\n","        arr1.append((y_test_inverse[i:i+10].std()))"],"metadata":{"id":"VLgG7Idk5-SU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arr=np.array(arr)\n","arr1=np.array(arr1)\n","abs((1 - (arr1/arr))).mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5BGShnwr72v8","executionInfo":{"status":"ok","timestamp":1682241992991,"user_tz":-330,"elapsed":420,"user":{"displayName":"Vatsal Chowdhary","userId":"11960625794539825838"}},"outputId":"dcdf98fd-7e88-42a0-fb7a-65d2cb8aef4c"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.31780056590387734"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["print(type(y_hat_inverse))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JlFEEYsGb7Jh","executionInfo":{"status":"ok","timestamp":1682242106229,"user_tz":-330,"elapsed":402,"user":{"displayName":"Vatsal Chowdhary","userId":"11960625794539825838"}},"outputId":"3080fe26-04f0-4071-bb73-f006380579d1"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n"]}]},{"cell_type":"code","source":["file = open(\"filebitcoin.txt\", \"w+\")\n"," \n","# Saving the array in a text file\n","content = str(y_hat_inverse)\n","file.write(content)\n","file.close()"],"metadata":{"id":"cFHZ9qiBb9_5","executionInfo":{"status":"ok","timestamp":1682242208778,"user_tz":-330,"elapsed":400,"user":{"displayName":"Vatsal Chowdhary","userId":"11960625794539825838"}}},"execution_count":37,"outputs":[]}]}