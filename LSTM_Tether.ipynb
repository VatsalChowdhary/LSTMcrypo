{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from datetime import datetime, timedelta\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from arch import arch_model\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","import numpy as np\n","from arch.__future__ import reindexing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout, Bidirectional, Activation, LSTM\n","from keras.optimizers import Adam\n","import keras\n","import datetime\n","from scipy.stats import norm"],"metadata":{"id":"LGx8mriqqfw8","executionInfo":{"status":"ok","timestamp":1682244337340,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vatsal Chowdhary","userId":"11960625794539825838"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gaqo-3SVqBp_","executionInfo":{"status":"ok","timestamp":1682234901077,"user_tz":-330,"elapsed":14725,"user":{"displayName":"Vatsal Chowdhary","userId":"11960625794539825838"}},"outputId":"3f8bd01f-bba3-487b-e203-9ba57d967399"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","25/25 [==============================] - 62s 2s/step - loss: 0.1121 - val_loss: 0.0124\n","Epoch 2/50\n","25/25 [==============================] - 49s 2s/step - loss: 0.0333 - val_loss: 0.0425\n","Epoch 3/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0271 - val_loss: 0.0017\n","Epoch 4/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0278 - val_loss: 0.0181\n","Epoch 5/50\n","25/25 [==============================] - 46s 2s/step - loss: 0.0278 - val_loss: 0.0140\n","Epoch 6/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0216 - val_loss: 0.0020\n","Epoch 7/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0227 - val_loss: 0.0159\n","Epoch 8/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0211 - val_loss: 0.0046\n","Epoch 9/50\n","25/25 [==============================] - 49s 2s/step - loss: 0.0225 - val_loss: 0.0041\n","Epoch 10/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0298 - val_loss: 0.0202\n","Epoch 11/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0255 - val_loss: 0.0177\n","Epoch 12/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0497 - val_loss: 0.0288\n","Epoch 13/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0313 - val_loss: 0.0272\n","Epoch 14/50\n","25/25 [==============================] - 49s 2s/step - loss: 0.0411 - val_loss: 0.0284\n","Epoch 15/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0280 - val_loss: 0.0204\n","Epoch 16/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0322 - val_loss: 0.0045\n","Epoch 17/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0294 - val_loss: 0.0083\n","Epoch 18/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0256 - val_loss: 0.0181\n","Epoch 19/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0318 - val_loss: 0.0044\n","Epoch 20/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0248 - val_loss: 0.0156\n","Epoch 21/50\n","25/25 [==============================] - 49s 2s/step - loss: 0.0354 - val_loss: 0.0313\n","Epoch 22/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0274 - val_loss: 0.0029\n","Epoch 23/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0233 - val_loss: 0.0061\n","Epoch 24/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0293 - val_loss: 0.0246\n","Epoch 25/50\n","25/25 [==============================] - 46s 2s/step - loss: 0.0257 - val_loss: 0.0022\n","Epoch 26/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0258 - val_loss: 0.0047\n","Epoch 27/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0224 - val_loss: 0.0145\n","Epoch 28/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0327 - val_loss: 0.0196\n","Epoch 29/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0412 - val_loss: 0.0322\n","Epoch 30/50\n","25/25 [==============================] - 46s 2s/step - loss: 0.0268 - val_loss: 0.0171\n","Epoch 31/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0242 - val_loss: 0.0115\n","Epoch 32/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0222 - val_loss: 0.0051\n","Epoch 33/50\n","25/25 [==============================] - 46s 2s/step - loss: 0.0247 - val_loss: 0.0156\n","Epoch 34/50\n","25/25 [==============================] - 49s 2s/step - loss: 0.0235 - val_loss: 0.0075\n","Epoch 35/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0232 - val_loss: 0.0019\n","Epoch 36/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0234 - val_loss: 0.0032\n","Epoch 37/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0227 - val_loss: 0.0040\n","Epoch 38/50\n","25/25 [==============================] - 46s 2s/step - loss: 0.0223 - val_loss: 0.0014\n","Epoch 39/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0227 - val_loss: 0.0050\n","Epoch 40/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0213 - val_loss: 0.0097\n","Epoch 41/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0237 - val_loss: 0.0074\n","Epoch 42/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0204 - val_loss: 0.0112\n","Epoch 43/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0269 - val_loss: 0.0206\n","Epoch 44/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0291 - val_loss: 0.0229\n","Epoch 45/50\n","25/25 [==============================] - 49s 2s/step - loss: 0.0278 - val_loss: 0.0169\n","Epoch 46/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0271 - val_loss: 0.0057\n","Epoch 47/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0238 - val_loss: 0.0028\n","Epoch 48/50\n","25/25 [==============================] - 48s 2s/step - loss: 0.0214 - val_loss: 0.0023\n","Epoch 49/50\n","25/25 [==============================] - 46s 2s/step - loss: 0.0215 - val_loss: 0.0026\n","Epoch 50/50\n","25/25 [==============================] - 47s 2s/step - loss: 0.0191 - val_loss: 0.0029\n","3/3 [==============================] - 4s 251ms/step\n"]}],"source":["csv_path = \"https://raw.githubusercontent.com/curiousily/Deep-Learning-For-Hackers/master/data/3.stock-prediction/BTC-USD.csv\"\n","df = pd.read_csv('tether.csv', parse_dates=['Date'])\n","df = df.sort_values('Date')\n","scaler = MinMaxScaler()\n","\n","close_price = df.Close.values.reshape(-1, 1)\n","\n","scaled_close = scaler.fit_transform(close_price)\n","scaled_close = scaled_close[~np.isnan(scaled_close)]\n","scaled_close = scaled_close.reshape(-1, 1)\n","SEQ_LEN = 100\n","\n","def to_sequences(data, seq_len):\n","    d = []\n","\n","    for index in range(len(data) - seq_len):\n","        d.append(data[index: index + seq_len])\n","\n","    return np.array(d)\n","\n","def preprocess(data_raw, seq_len, train_split):\n","\n","    data = to_sequences(data_raw, seq_len)\n","\n","    num_train = int(train_split * data.shape[0])\n","\n","    X_train = data[:num_train, :-1, :]\n","    y_train = data[:num_train, -1, :]\n","\n","    X_test = data[num_train:, :-1, :]\n","    y_test = data[num_train:, -1, :]\n","\n","    return X_train, y_train, X_test, y_test\n","\n","\n","X_train, y_train, X_test, y_test =\\\n"," preprocess(scaled_close, SEQ_LEN, train_split = 0.95)\n","DROPOUT = 0.2\n","WINDOW_SIZE = SEQ_LEN - 1\n","model = keras.Sequential()\n","model.add(Bidirectional(LSTM(WINDOW_SIZE, return_sequences=True),\n","  input_shape=(WINDOW_SIZE, X_train.shape[-1])\n","))\n","model.add(Dropout(rate=DROPOUT))\n","\n","model.add(Bidirectional(\n","  LSTM((WINDOW_SIZE * 2), return_sequences=True)\n","))\n","model.add(Dropout(rate=DROPOUT))\n","\n","model.add(Bidirectional(\n","  LSTM(WINDOW_SIZE, return_sequences=False)\n","))\n","\n","model.add(Dense(units=1))\n","\n","model.add(Activation('linear'))\n","BATCH_SIZE = 64\n","\n","model.compile(\n","    loss='mean_absolute_error',\n","    optimizer='adam'\n",")\n","\n","history = model.fit(\n","    X_train,\n","    y_train,\n","    epochs=50,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    validation_split=0.1\n",")\n","\n","y_hat = model.predict(X_test)\n","y_test_inverse = scaler.inverse_transform(y_test)\n","y_hat_inverse = scaler.inverse_transform(y_hat)"]},{"cell_type":"code","source":["arr = []\n","for i in range(0, len(y_hat_inverse)-10):\n","        arr.append((y_hat_inverse[i:i+10].std()))\n","arr1 = []\n","for i in range(0, len(y_test_inverse)-10):\n","        arr1.append((y_test_inverse[i:i+10].std()))\n","arr=np.array(arr)\n","arr1=np.array(arr1)\n","abs((1 - (arr/arr1))).mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rBJ4vBePBoTC","executionInfo":{"status":"ok","timestamp":1682237697287,"user_tz":-330,"elapsed":885,"user":{"displayName":"Vatsal Chowdhary","userId":"11960625794539825838"}},"outputId":"679cac09-d143-47af-d37e-72859e51f7ff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7155478262761814"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":[],"metadata":{"id":"Gd2KBQ6ykrX1"},"execution_count":null,"outputs":[]}]}