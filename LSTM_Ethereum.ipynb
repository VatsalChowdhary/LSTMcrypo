{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSMO+ycrtraOFEQHEHwTKz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from datetime import datetime, timedelta\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from arch import arch_model\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","import numpy as np\n","from arch.__future__ import reindexing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout, Bidirectional, Activation, LSTM\n","from keras.optimizers import Adam\n","import keras"],"metadata":{"id":"I2UKilw6qWYN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"28P2TVcMqMBD","executionInfo":{"status":"ok","timestamp":1682238255288,"user_tz":-330,"elapsed":2982933,"user":{"displayName":"Vatsal Chowdhary","userId":"11960625794539825838"}},"outputId":"e115985b-8cab-4a71-b297-095cea06b4cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","31/31 [==============================] - 76s 2s/step - loss: 0.0350 - val_loss: 0.0681\n","Epoch 2/50\n","31/31 [==============================] - 58s 2s/step - loss: 0.0610 - val_loss: 0.1163\n","Epoch 3/50\n","31/31 [==============================] - 58s 2s/step - loss: 0.0366 - val_loss: 0.1847\n","Epoch 4/50\n","31/31 [==============================] - 59s 2s/step - loss: 0.0387 - val_loss: 0.0713\n","Epoch 5/50\n","31/31 [==============================] - 58s 2s/step - loss: 0.0828 - val_loss: 0.1360\n","Epoch 6/50\n","31/31 [==============================] - 61s 2s/step - loss: 0.0493 - val_loss: 0.1240\n","Epoch 7/50\n","31/31 [==============================] - 59s 2s/step - loss: 0.0379 - val_loss: 0.0824\n","Epoch 8/50\n","31/31 [==============================] - 58s 2s/step - loss: 0.0169 - val_loss: 0.0772\n","Epoch 9/50\n","31/31 [==============================] - 57s 2s/step - loss: 0.0396 - val_loss: 0.0900\n","Epoch 10/50\n","31/31 [==============================] - 59s 2s/step - loss: 0.0483 - val_loss: 0.0702\n","Epoch 11/50\n","31/31 [==============================] - 57s 2s/step - loss: 0.0571 - val_loss: 0.1720\n","Epoch 12/50\n","31/31 [==============================] - 61s 2s/step - loss: 0.0251 - val_loss: 0.0399\n","Epoch 13/50\n","31/31 [==============================] - 58s 2s/step - loss: 0.0268 - val_loss: 0.0588\n","Epoch 14/50\n","31/31 [==============================] - 59s 2s/step - loss: 0.0243 - val_loss: 0.0410\n","Epoch 15/50\n","31/31 [==============================] - 58s 2s/step - loss: 0.0216 - val_loss: 0.0564\n","Epoch 16/50\n","31/31 [==============================] - 59s 2s/step - loss: 0.0325 - val_loss: 0.0449\n","Epoch 17/50\n","31/31 [==============================] - 57s 2s/step - loss: 0.0147 - val_loss: 0.0555\n","Epoch 18/50\n","31/31 [==============================] - 59s 2s/step - loss: 0.0284 - val_loss: 0.0383\n","Epoch 19/50\n","31/31 [==============================] - 57s 2s/step - loss: 0.0463 - val_loss: 0.0828\n","Epoch 20/50\n","31/31 [==============================] - 58s 2s/step - loss: 0.0193 - val_loss: 0.0425\n","Epoch 21/50\n","31/31 [==============================] - 60s 2s/step - loss: 0.0247 - val_loss: 0.0839\n","Epoch 22/50\n","31/31 [==============================] - 58s 2s/step - loss: 0.0408 - val_loss: 0.0383\n","Epoch 23/50\n","31/31 [==============================] - 58s 2s/step - loss: 0.0132 - val_loss: 0.0423\n","Epoch 24/50\n","31/31 [==============================] - 57s 2s/step - loss: 0.0272 - val_loss: 0.0400\n","Epoch 25/50\n","31/31 [==============================] - 59s 2s/step - loss: 0.0470 - val_loss: 0.1318\n","Epoch 26/50\n","31/31 [==============================] - 57s 2s/step - loss: 0.0505 - val_loss: 0.2121\n","Epoch 27/50\n","31/31 [==============================] - 59s 2s/step - loss: 0.0205 - val_loss: 0.0341\n","Epoch 28/50\n","31/31 [==============================] - 58s 2s/step - loss: 0.0223 - val_loss: 0.0576\n","Epoch 29/50\n","31/31 [==============================] - 62s 2s/step - loss: 0.0241 - val_loss: 0.0468\n","Epoch 30/50\n","31/31 [==============================] - 58s 2s/step - loss: 0.0139 - val_loss: 0.0373\n","Epoch 31/50\n","31/31 [==============================] - 61s 2s/step - loss: 0.0230 - val_loss: 0.0367\n","Epoch 32/50\n","31/31 [==============================] - 57s 2s/step - loss: 0.0463 - val_loss: 0.0801\n","Epoch 33/50\n","31/31 [==============================] - 59s 2s/step - loss: 0.0156 - val_loss: 0.0381\n","Epoch 34/50\n","31/31 [==============================] - 58s 2s/step - loss: 0.0216 - val_loss: 0.0401\n","Epoch 35/50\n","31/31 [==============================] - 60s 2s/step - loss: 0.0490 - val_loss: 0.1121\n","Epoch 36/50\n","31/31 [==============================] - 58s 2s/step - loss: 0.0365 - val_loss: 0.0560\n","Epoch 37/50\n","31/31 [==============================] - 60s 2s/step - loss: 0.0323 - val_loss: 0.0456\n","Epoch 38/50\n","31/31 [==============================] - 59s 2s/step - loss: 0.0329 - val_loss: 0.0400\n","Epoch 39/50\n","31/31 [==============================] - 60s 2s/step - loss: 0.0282 - val_loss: 0.0830\n","Epoch 40/50\n","31/31 [==============================] - 59s 2s/step - loss: 0.0494 - val_loss: 0.2593\n","Epoch 41/50\n","31/31 [==============================] - 61s 2s/step - loss: 0.0141 - val_loss: 0.0595\n","Epoch 42/50\n","31/31 [==============================] - 59s 2s/step - loss: 0.0348 - val_loss: 0.1148\n","Epoch 43/50\n","31/31 [==============================] - 60s 2s/step - loss: 0.0175 - val_loss: 0.0507\n","Epoch 44/50\n","31/31 [==============================] - 62s 2s/step - loss: 0.0296 - val_loss: 0.0599\n","Epoch 45/50\n","31/31 [==============================] - 59s 2s/step - loss: 0.0235 - val_loss: 0.0560\n","Epoch 46/50\n","31/31 [==============================] - 60s 2s/step - loss: 0.0493 - val_loss: 0.3011\n","Epoch 47/50\n","31/31 [==============================] - 60s 2s/step - loss: 0.0148 - val_loss: 0.0394\n","Epoch 48/50\n","31/31 [==============================] - 60s 2s/step - loss: 0.0181 - val_loss: 0.0413\n","Epoch 49/50\n","31/31 [==============================] - 61s 2s/step - loss: 0.0372 - val_loss: 0.0608\n","Epoch 50/50\n","31/31 [==============================] - 59s 2s/step - loss: 0.0377 - val_loss: 0.1761\n","4/4 [==============================] - 4s 420ms/step\n"]}],"source":["csv_path = \"https://raw.githubusercontent.com/curiousily/Deep-Learning-For-Hackers/master/data/3.stock-prediction/BTC-USD.csv\"\n","df = pd.read_csv('ethereum.csv', parse_dates=['Date'])\n","df = df.sort_values('Date')\n","scaler = MinMaxScaler()\n","\n","close_price = df.Close.values.reshape(-1, 1)\n","\n","scaled_close = scaler.fit_transform(close_price)\n","scaled_close = scaled_close[~np.isnan(scaled_close)]\n","scaled_close = scaled_close.reshape(-1, 1)\n","SEQ_LEN = 100\n","\n","def to_sequences(data, seq_len):\n","    d = []\n","\n","    for index in range(len(data) - seq_len):\n","        d.append(data[index: index + seq_len])\n","\n","    return np.array(d)\n","\n","def preprocess(data_raw, seq_len, train_split):\n","\n","    data = to_sequences(data_raw, seq_len)\n","\n","    num_train = int(train_split * data.shape[0])\n","\n","    X_train = data[:num_train, :-1, :]\n","    y_train = data[:num_train, -1, :]\n","\n","    X_test = data[num_train:, :-1, :]\n","    y_test = data[num_train:, -1, :]\n","\n","    return X_train, y_train, X_test, y_test\n","\n","\n","X_train, y_train, X_test, y_test =\\\n"," preprocess(scaled_close, SEQ_LEN, train_split = 0.95)\n","DROPOUT = 0.2\n","WINDOW_SIZE = SEQ_LEN - 1\n","model = keras.Sequential()\n","model.add(Bidirectional(LSTM(WINDOW_SIZE, return_sequences=True),\n","  input_shape=(WINDOW_SIZE, X_train.shape[-1])\n","))\n","model.add(Dropout(rate=DROPOUT))\n","\n","model.add(Bidirectional(\n","  LSTM((WINDOW_SIZE * 2), return_sequences=True)\n","))\n","model.add(Dropout(rate=DROPOUT))\n","\n","model.add(Bidirectional(\n","  LSTM(WINDOW_SIZE, return_sequences=False)\n","))\n","\n","model.add(Dense(units=1))\n","\n","model.add(Activation('linear'))\n","BATCH_SIZE = 64\n","\n","model.compile(\n","    loss='mean_absolute_error',\n","    optimizer='adam'\n",")\n","\n","history = model.fit(\n","    X_train,\n","    y_train,\n","    epochs=50,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    validation_split=0.1\n",")\n","\n","y_hat = model.predict(X_test)\n","y_test_inverse = scaler.inverse_transform(y_test)\n","y_hat_inverse = scaler.inverse_transform(y_hat)"]},{"cell_type":"code","source":["arr = []\n","for i in range(0, len(y_hat_inverse)-10):\n","        arr.append((y_hat_inverse[i:i+10].std()))\n","arr1 = []\n","for i in range(0, len(y_test_inverse)-10):\n","        arr1.append((y_test_inverse[i:i+10].std()))\n","arr=np.array(arr)\n","arr1=np.array(arr1)\n","abs((1 - (arr/arr1))).mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bIhLsNzDPd3i","executionInfo":{"status":"ok","timestamp":1682245842337,"user_tz":-330,"elapsed":718,"user":{"displayName":"Vatsal Chowdhary","userId":"11960625794539825838"}},"outputId":"75256830-47f7-4598-d35d-7d2f0cf8f7fd"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.41426018492851313"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["print(y_test_inverse)\n","file = open(\"file1.txt\", \"w+\")\n"," \n","# Saving the array in a text file\n","content = str(y_test_inverse)\n","file.write(content)\n","file.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89lkXVV9bbTe","executionInfo":{"status":"ok","timestamp":1682242142548,"user_tz":-330,"elapsed":567,"user":{"displayName":"Vatsal Chowdhary","userId":"11960625794539825838"}},"outputId":"631e8641-39e4-4ad7-c096-69f330f66831"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[[2856.01]\n"," [2781.47]\n"," [2940.7 ]\n"," [2747.46]\n"," [2692.88]\n"," [2636.03]\n"," [2519.98]\n"," [2229.1 ]\n"," [2342.3 ]\n"," [2080.79]\n"," [1955.36]\n"," [2009.53]\n"," [2056.3 ]\n"," [2145.86]\n"," [2022.93]\n"," [2091.14]\n"," [1912.12]\n"," [2019.34]\n"," [1959.85]\n"," [1975.12]\n"," [2043.19]\n"," [1972.93]\n"," [1979.35]\n"," [1942.91]\n"," [1793.42]\n"," [1724.3 ]\n"," [1792.68]\n"," [1813.56]\n"," [1998.46]\n"," [1941.79]\n"," [1818.07]\n"," [1834.64]\n"," [1775.29]\n"," [1804.37]\n"," [1806.71]\n"," [1859.99]\n"," [1813.72]\n"," [1793.  ]\n"," [1788.06]\n"," [1663.02]\n"," [1531.42]\n"," [1435.46]\n"," [1206.67]\n"," [1210.84]\n"," [1237.92]\n"," [1068.49]\n"," [1086.47]\n"," [ 995.61]\n"," [1128.39]\n"," [1128.32]\n"," [1125.96]\n"," [1049.02]\n"," [1144.19]\n"," [1225.03]\n"," [1241.76]\n"," [1198.03]\n"," [1190.84]\n"," [1143.97]\n"," [1099.51]\n"," [1069.05]\n"," [1058.94]\n"," [1066.6 ]\n"," [1074.08]\n"," [1151.19]\n"," [1133.9 ]\n"," [1186.45]\n"," [1238.15]\n"," [1216.33]\n"," [1216.94]\n"," [1167.35]\n"," [1096.43]\n"," [1038.56]\n"," [1115.83]\n"," [1192.75]\n"," [1231.03]\n"," [1356.08]\n"," [1337.85]\n"," [1584.77]\n"," [1543.5 ]\n"," [1520.64]\n"," [1575.68]\n"," [1534.85]\n"," [1549.61]\n"," [1598.19]\n"," [1438.52]\n"," [1450.7 ]\n"," [1636.01]\n"," [1726.01]\n"," [1720.77]\n"," [1695.97]\n"," [1680.  ]\n"," [1630.1 ]\n"," [1631.48]\n"," [1618.08]\n"," [1606.94]\n"," [1737.71]\n"," [1690.27]\n"," [1700.29]\n"," [1778.42]\n"," [1702.8 ]\n"," [1853.46]\n"," [1880.28]\n"," [1957.63]\n"," [1983.5 ]\n"," [1935.1 ]\n"," [1900.25]\n"," [1876.7 ]\n"," [1834.18]\n"," [1846.51]\n"," [1609.48]\n"," [1575.6 ]\n"," [1618.25]\n"," [1626.75]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ZW5jpAnWbf8n"},"execution_count":null,"outputs":[]}]}